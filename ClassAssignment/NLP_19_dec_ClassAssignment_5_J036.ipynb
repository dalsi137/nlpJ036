{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP 19 dec ClassAssignment 5 J036",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dalsi137/nlpJ036/blob/master/ClassAssignment/NLP_19_dec_ClassAssignment_5_J036.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkY58u-WFq8l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "950af97f-0e1c-4972-f0c8-7ef86eccd3a2"
      },
      "source": [
        "!pip install word2vec"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting word2vec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/51/5e2782b204015c8aef0ac830297c2f2735143ec90f592b9b3b909bb89757/word2vec-0.10.2.tar.gz (60kB)\n",
            "\r\u001b[K     |█████▍                          | 10kB 18.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from word2vec) (1.12.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from word2vec) (0.29.14)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from word2vec) (1.17.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from word2vec) (1.3.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from word2vec) (0.21.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->word2vec) (0.14.1)\n",
            "Building wheels for collected packages: word2vec\n",
            "  Building wheel for word2vec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2vec: filename=word2vec-0.10.2-cp36-cp36m-linux_x86_64.whl size=128655 sha256=613f0e38d9f1fe02593302c45ad0f59d15ffa1ebdd68be64ed7ebecd541b958d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/9f/06/aec42532c9c37e05f936d4d586b15cfdfc9f2ffb62bd7fed1c\n",
            "Successfully built word2vec\n",
            "Installing collected packages: word2vec\n",
            "Successfully installed word2vec-0.10.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuPd3wF8F18G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import stopwords\n",
        "from itertools import combinations\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKzP2k5jF4g-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv(\"https://raw.githubusercontent.com/zfz/twitter_corpus/master/full-corpus.csv\")\n",
        "twit = data.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0W4lbr6GAN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twit['tokenText'] = twit['TweetText'].apply(lambda x: list(set(x.translate(str.maketrans('','', string.punctuation)).split())))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7o1Pq2fGAxz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "eb7d5c2e-4e78-4032-d495-db79bbb5fefd"
      },
      "source": [
        "twit['tokenText']"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [to, get, do, Apple, that, be, is, iphone, and...\n",
              "1       [to, announced, Apple, the, just, carrier, wil...\n",
              "2       [Hilarious, apple, duet, youtube, guy, sums, w...\n",
              "3       [RIM, to, easy, you, ya, Apple, See, me, it, t...\n",
              "4       [apple, was, twitter, that, just, realized, re...\n",
              "                              ...                        \n",
              "5108                         [twitter, copè, me, re, con]\n",
              "5109    [noches, los, Buenas, twitter, quierooo, gente...\n",
              "5110    [mala, yo, ponerce, la, twitter, me, de, voy, ...\n",
              "5111    [vinda, Twitter, por, ao, meu, dou, followback...\n",
              "5112    [humana, Eles, tudo, seguiram, arrastaram, RT,...\n",
              "Name: tokenText, Length: 5113, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNo3bB0pGDhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bagofwords = [[i] for i in list(set([y for x in twit['tokenText'] for y in x]))] \n",
        "model3 = Word2Vec(list(bagofwords), min_count=1,size= 50,workers=3, window =3, sg = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE-gP7xLGGXo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "outputId": "ff994e83-53d6-4e96-fc18-4e21453b5ed4"
      },
      "source": [
        "for i in bagofwords[0:10]:\n",
        "  for j in bagofwords[0:10]:\n",
        "    if j>i:\n",
        "      print(i[0],j[0],' : ',model3.wv.similarity(i[0],j[0]))\n",
        "    else:\n",
        "      continue"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fav RTzZzZzZzZzZzZzZzZzZzZ  :  0.20040567\n",
            "Fav dawns  :  -0.03976448\n",
            "Fav Oo  :  -0.063269064\n",
            "Fav slaps  :  0.052498713\n",
            "Fav that  :  0.15229765\n",
            "Fav GPlus  :  -0.23538394\n",
            "Fav httptcocuoW78du  :  -0.07760212\n",
            "Fav consolidation  :  -0.1599749\n",
            "Fav Hear  :  0.17595129\n",
            "RTzZzZzZzZzZzZzZzZzZzZ dawns  :  -0.06581731\n",
            "RTzZzZzZzZzZzZzZzZzZzZ slaps  :  0.34174716\n",
            "RTzZzZzZzZzZzZzZzZzZzZ that  :  0.009856976\n",
            "RTzZzZzZzZzZzZzZzZzZzZ httptcocuoW78du  :  -0.32944328\n",
            "RTzZzZzZzZzZzZzZzZzZzZ consolidation  :  -0.29477793\n",
            "dawns slaps  :  -0.13631359\n",
            "dawns that  :  -0.15722129\n",
            "dawns httptcocuoW78du  :  -0.11086406\n",
            "Oo RTzZzZzZzZzZzZzZzZzZzZ  :  0.10313867\n",
            "Oo dawns  :  0.08726537\n",
            "Oo slaps  :  0.18429703\n",
            "Oo that  :  0.07772024\n",
            "Oo httptcocuoW78du  :  -0.18885605\n",
            "Oo consolidation  :  0.16778795\n",
            "slaps that  :  -0.0060808845\n",
            "GPlus RTzZzZzZzZzZzZzZzZzZzZ  :  0.034548495\n",
            "GPlus dawns  :  0.17181022\n",
            "GPlus Oo  :  0.07958205\n",
            "GPlus slaps  :  0.02732121\n",
            "GPlus that  :  0.017791422\n",
            "GPlus httptcocuoW78du  :  0.2017165\n",
            "GPlus consolidation  :  0.2836694\n",
            "GPlus Hear  :  -0.1334142\n",
            "httptcocuoW78du slaps  :  -0.14508116\n",
            "httptcocuoW78du that  :  -0.021896401\n",
            "consolidation dawns  :  -0.028207744\n",
            "consolidation slaps  :  0.13387847\n",
            "consolidation that  :  0.0298445\n",
            "consolidation httptcocuoW78du  :  0.17153487\n",
            "Hear RTzZzZzZzZzZzZzZzZzZzZ  :  0.02949689\n",
            "Hear dawns  :  0.029361451\n",
            "Hear Oo  :  0.18731081\n",
            "Hear slaps  :  0.0807088\n",
            "Hear that  :  0.08762764\n",
            "Hear httptcocuoW78du  :  0.0742257\n",
            "Hear consolidation  :  -0.0938087\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjjhXHqSGJOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}